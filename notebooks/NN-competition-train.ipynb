{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69486b28-5148-48ab-ae47-8ea58a7fb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm==1.0.9\n",
    "# !pip install albumentations==1.4.14\n",
    "# !pip install torcheval==0.0.7\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0671889-2943-4530-856b-fa0415d66736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time, copy, gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import multiprocessing as mp\n",
    "\n",
    "from torcheval.metrics.functional import binary_auroc, multiclass_auroc\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import hashlib\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('./src')\n",
    "from utils import set_seed, visualize_augmentations_positive, print_trainable_parameters\n",
    "from models import setup_model\n",
    "from training import fetch_scheduler, train_one_epoch, valid_one_epoch, run_training, get_nth_test_step\n",
    "from models import ISICModel, ISICModelEdgnet, setup_model\n",
    "from datasets import ISICDatasetSamplerW, ISICDatasetSampler, ISICDatasetSimple, ISICDatasetSamplerMulticlass, prepare_loaders\n",
    "from augmentations import get_augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ff70a2-7e1d-48b5-9564-f18ca382d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Tesla T4\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Set up device and random seed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7803a16c-0893-4dee-98ac-ca017bde86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = \"/data/original\"\n",
    "original_root = Path('/data/original')\n",
    "\n",
    "data_artifacts = \"/data/artifacts\"\n",
    "os.makedirs(data_artifacts, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d762d6ea-d3bd-411a-8712-eaa1a01b178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2238/117739829.py:5: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(train_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive cases: 393\n",
      "Number of negative cases: 400666\n",
      "Ratio of negative to positive cases: 1019.51:1\n"
     ]
    }
   ],
   "source": [
    "# Set the HDF5 file path\n",
    "TRAIN_HDF5_FILE_PATH = original_root / 'train-image.hdf5'\n",
    "\n",
    "train_path = original_root / 'train-metadata.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train[\"path\"] = '/data/original/train-image/image/' + df_train['isic_id'] + \".jpg\"\n",
    "original_positive_cases = df_train['target'].sum()\n",
    "original_total_cases = len(df_train)\n",
    "original_positive_ratio = original_positive_cases / original_total_cases\n",
    "\n",
    "print(f\"Number of positive cases: {original_positive_cases}\")\n",
    "print(f\"Number of negative cases: {original_total_cases - original_positive_cases}\")\n",
    "print(f\"Ratio of negative to positive cases: {(original_total_cases - original_positive_cases) / original_positive_cases:.2f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11c7c5-040f-4170-984a-8123025bd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EDGENEXT\" # \"EVA\"\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42 if MODEL_NAME == 'EVA' else 1997,\n",
    "    \"epochs\": 500,\n",
    "    \"img_size\": 336 if MODEL_NAME == 'EVA' else 256,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 2000,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"group_col\": 'patient_id',\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "model_name = \"eva02_small_patch14_336.mim_in22k_ft_in1k\" if MODEL_NAME == 'EVA' else \"edgenext_base.in21k_ft_in1k\"\n",
    "checkpoint_path = None\n",
    "\n",
    "\n",
    "if MODEL_NAME == 'EVA':\n",
    "    ISICModelPrep = ISICModel\n",
    "else:\n",
    "    ISICModelPrep = ISICModelEdgnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b6f4bd-2bbb-45ce-a8cb-d31dac99b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/isic-2024/src/augmentations.py:16: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0)),\n",
      "/opt/pytorch/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/ubuntu/isic-2024/src/augmentations.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n"
     ]
    }
   ],
   "source": [
    "data_transforms = get_augmentations(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e655c2e6-541b-43d4-a9cb-ccec94436522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, targets):\n",
    "    return nn.BCELoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485bbd9d-135d-4e0d-9032-f4b805d344bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_custom_data = f\"../data/artifacts/syntetic_custom_base_{CONFIG['seed']}\"\n",
    "# os.makedirs(synthetic_custom_data, exist_ok=True)\n",
    "\n",
    "# tsp = StratifiedGroupKFold(2, shuffle=True, random_state=CONFIG['seed'])\n",
    "# metrics_ev_df = []\n",
    "# test_forecast = []\n",
    "# val_forecast = []\n",
    "# for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[CONFIG[\"group_col\"]])):\n",
    "#     fold_df_train = df_train.iloc[train_index].reset_index(drop=True)\n",
    "#     fold_df_valid = df_train.iloc[val_index].reset_index(drop=True)\n",
    "#     synthetic_custom_data_pr = os.path.join(synthetic_custom_data, str(fold_n))\n",
    "#     os.makedirs(synthetic_custom_data_pr, exist_ok=True)\n",
    "\n",
    "#     for fn in fold_df_train[fold_df_train.target==1].isic_id.values:\n",
    "#         if fn not in images_to_include:\n",
    "#             continue\n",
    "#         img = Image.open(os.path.join('../data/original/train-image/image', fn + \".jpg\"))\n",
    "#         img.save(os.path.join(synthetic_custom_data_pr, fn + \".png\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3241c3a9-8c31-454d-9813-c70b624addf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = f\"./models/oof_{MODEL_NAME.lower()}_base\"\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b52d09c-81ca-4151-9988-85257da235d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(drop_path_rate, drop_rate, models_folder, model_maker):\n",
    "    tsp = StratifiedGroupKFold(5, shuffle=True, random_state=CONFIG['seed'])\n",
    "    results_list = []\n",
    "    fold_df_valid_list = []\n",
    "    for fold_n, (train_index, val_index) in enumerate(tsp.split(df_train, y=df_train.target, groups=df_train[CONFIG[\"group_col\"]])):\n",
    "        fold_df_train = df_train.iloc[train_index].reset_index(drop=True)\n",
    "        fold_df_valid = df_train.iloc[val_index].reset_index(drop=True)\n",
    "        set_seed(CONFIG['seed'])\n",
    "        model = setup_model(model_name, drop_path_rate=drop_path_rate, drop_rate=drop_rate, model_maker=model_maker)\n",
    "        print_trainable_parameters(model)\n",
    "\n",
    "        train_loader, valid_loader = prepare_loaders(fold_df_train, fold_df_valid, CONFIG, data_transforms)\n",
    "    \n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                           weight_decay=CONFIG['weight_decay'])\n",
    "        scheduler = fetch_scheduler(optimizer, CONFIG)\n",
    "    \n",
    "        model, history = run_training(\n",
    "            train_loader, valid_loader,\n",
    "            model, optimizer, scheduler,\n",
    "            device=CONFIG['device'],\n",
    "            num_epochs=CONFIG['epochs'],\n",
    "            CONFIG=CONFIG, \n",
    "            tolerance_max=20,\n",
    "            test_every_nth_step=lambda x: 5,\n",
    "            seed=CONFIG['seed'])\n",
    "        torch.save(model.state_dict(), os.path.join(models_folder, f\"model__{fold_n}\"))\n",
    "        results_list.append(np.max(history['Valid Kaggle metric']))\n",
    "\n",
    "        val_epoch_loss, val_epoch_auroc, val_epoch_custom_metric, tmp_predictions_all, tmp_targets_all = valid_one_epoch(\n",
    "            model, \n",
    "            valid_loader, \n",
    "            device=CONFIG['device'], \n",
    "            epoch=1, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            use_custom_score=True,\n",
    "            metric_function=binary_auroc, \n",
    "            num_classes=1,\n",
    "            return_preds=True)\n",
    "\n",
    "        fold_df_valid['tmp_targets_all'] = tmp_targets_all\n",
    "        fold_df_valid['tmp_predictions_all'] = tmp_predictions_all\n",
    "        fold_df_valid['fold_n'] = fold_n\n",
    "        fold_df_valid_list.append(fold_df_valid)\n",
    "    fold_df_valid_list = pd.concat(fold_df_valid_list).reset_index(drop=True)\n",
    "    return results_list, fold_df_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a2a0e-6b7a-4f99-87bd-41e35ee528ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166650d75192411c80e44878a65efd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/88.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 21744385 || all params: 21744385 || trainable%: 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████| 19/19 [00:27<00:00,  1.43s/it, Epoch=1, LR=0.0001, Train_Auroc=0.494, Train_Loss=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:23<00:00,  1.25s/it, Epoch=2, LR=9.99e-5, Train_Auroc=0.507, Train_Loss=0.708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:23<00:00,  1.26s/it, Epoch=3, LR=9.98e-5, Train_Auroc=0.575, Train_Loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=4, LR=9.96e-5, Train_Auroc=0.572, Train_Loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=5, LR=9.94e-5, Train_Auroc=0.556, Train_Loss=0.695]\n",
      "100%|████████████████████████████████████████████| 1112/1112 [13:21<00:00,  1.39it/s, Epoch=5, LR=9.94e-5, Valid_Auroc=0.508, Valid_Loss=0.541]\n",
      "/opt/pytorch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:990: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  _warn_get_lr_called_within_step(self)\n",
      "/opt/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (-inf ---> 0.05113914670231129)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=6, LR=9.92e-5, Train_Auroc=0.634, Train_Loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=7, LR=9.89e-5, Train_Auroc=0.667, Train_Loss=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=8, LR=9.86e-5, Train_Auroc=0.721, Train_Loss=0.664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=9, LR=9.82e-5, Train_Auroc=0.75, Train_Loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=10, LR=9.78e-5, Train_Auroc=0.809, Train_Loss=0.562]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=12, LR=9.69e-5, Train_Auroc=0.829, Train_Loss=0.535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.26s/it, Epoch=13, LR=9.63e-5, Train_Auroc=0.848, Train_Loss=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=14, LR=9.57e-5, Train_Auroc=0.855, Train_Loss=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.27s/it, Epoch=15, LR=9.51e-5, Train_Auroc=0.882, Train_Loss=0.455]\n",
      "100%|███████████████████████████████████████████| 1112/1112 [13:10<00:00,  1.41it/s, Epoch=15, LR=9.51e-5, Valid_Auroc=0.528, Valid_Loss=0.386]\n",
      "/opt/pytorch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:990: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  _warn_get_lr_called_within_step(self)\n",
      "/opt/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC Improved (0.12893225665001556 ---> 0.13083583754694925)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=16, LR=9.45e-5, Train_Auroc=0.9, Train_Loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=17, LR=9.38e-5, Train_Auroc=0.887, Train_Loss=0.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=18, LR=9.3e-5, Train_Auroc=0.89, Train_Loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=19, LR=9.23e-5, Train_Auroc=0.901, Train_Loss=0.419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 19/19 [00:24<00:00,  1.28s/it, Epoch=20, LR=9.14e-5, Train_Auroc=0.877, Train_Loss=0.485]\n",
      "  1%|▏                                             | 6/1112 [00:04<13:30,  1.36it/s, Epoch=20, LR=9.14e-5, Valid_Auroc=0.583, Valid_Loss=0.549]"
     ]
    }
   ],
   "source": [
    "base_metrics, oof_forecasts = get_metrics(drop_path_rate=0, drop_rate=0, models_folder=folder_name, model_maker=ISICModelPrep)\n",
    "oof_forecasts.to_parquet(f'/data/artifacts/oof_forecasts_{MODEL_NAME.lower()}_base.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
